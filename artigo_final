# Assuming your data frame is named "yields"
# Make sure the column names are set appropriately

# Create an empty vector to store the optimal p for each time series
optimal_p_values <- numeric(121)

# Create an empty vector to store the variance of residuals for each time series
residual_variances <- numeric(121)

# Create an empty vector to store the intercepts for each time series
intercepts <- numeric(121)

# Loop through each time series
for (i in 1:121) {
  time_series <- yields[, i]
  
  # Initialize variables to store minimum BIC and optimal p
  min_bic <- Inf
  optimal_p <- 0
  
  # Try AR models with different values of p
  for (p in 1:10) {  # You can adjust the range of p as needed
    arima_model <- arima(time_series, order = c(p, 0, 0))
    bic <- AIC(arima_model, k = log(length(time_series)))
    
    # Update optimal p if current model has lower BIC
    if (bic < min_bic) {
      min_bic <- bic
      optimal_p <- p
    }
  }
  
  # Fit the final AR model with the optimal p
  final_arima_model <- arima(time_series, order = c(optimal_p, 0, 0))
  
  # Collect the variance of residuals
  residual_variances[i] <- var(resid(final_arima_model))
  
  # Collect the intercept of the ARIMA model
  intercepts[i] <- final_arima_model$coef[1]  # 1 corresponds to the intercept coefficient
  
  # Store the optimal p value
  optimal_p_values[i] <- optimal_p
}

# Display or use the results as needed
print(optimal_p_values)
print(residual_variances)
print(intercepts)



#========================================================================================================================================================================


yields_Y <- yields[2:nrow(yields),]
yields_X <- yields[1:(nrow(yields) - 1),]
yields_X <- cbind(intercept = 1, yields_X)



#========================================================================================================================================================================




# Step 1: Create lagged variables
yields_lagged <- cbind(yields[-(1:h), ], yields[1:(nrow(yields)-h), ])

# Step 2: Create column names for the lagged variables
colnames(yields_lagged) <- c(paste0("Y", 1:ncol(yields)), paste0("Ylag", 1:ncol(yields)))

# Step 3: Reshape data to long format
library(tidyr)
yields_long <- pivot_longer(as.data.frame(yields_lagged), cols = everything(), names_to = "variable", values_to = "value")

# Step 4: Fit the multivariate linear model
model <- lm(value ~ lag(value, h) + variable + lag(variable, h), data = yields_long)

# Step 5: Summary of the model
summary(model



#========================================================================================================================================================================




#Final goal: 
# matrix Psi_apt <- solve(solve(Sigma_apr) + t(X)%*%X)%*%(solve(Sigma_apr) %*% Psi_apr + t(X) %*% Y)

#Omega_apr is the covariance matrix of Phi_1h, which, based on (2), equals to:
Omega_apr <- matrix( nrow =  length(residual_variances), ncol =  length(residual_variances))
for (i in 1:length(residual_variances)) {
  for (j in 1:length(residual_variances)) {
    Omega_apr[i, j] <- residual_variances[i] / residual_variances[j]
  }
}

H <- 120
T <- nrow(yields)
N <- ncol(yields)

# X is the
X <- 

# There are H Y_h matrixes. For h = 1:H, Y_h is the (T-h)xN matrix: for i in 1:(T-h) Y[i,] <- yields[(h+i),]


Y_list <- list()
for (h in 1:H) {
  Y_h <- matrix(0, nrow = (T - h), ncol = N)
  Y_list[[h]] <- Y_h
}

# Accessing the matrices from the list
#for (h in 1:H) {
#  print(Y_list[[h]])
#}

for (h = 1:H) {
  for (i in 1:(T-h)) {
    Y_h[i,] <- yields[(h+i),]

# Psi_apr is the
Psi_apr <- 











